{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d7d3763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import welch\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, precision_recall_fscore_support\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24cbe25",
   "metadata": {},
   "source": [
    "# Creating the Like DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d40cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 keys: ['behavioralRatings']\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/behavioralRatings.mat\"\n",
    "with h5py.File(path, \"r\") as f:\n",
    "    print(\"HDF5 keys:\", list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db10a8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'h5py._hl.dataset.Dataset'>\n",
      "Shape: (2, 10, 20)\n",
      "Dtype: float64\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path, \"r\") as f:\n",
    "    br = f[\"behavioralRatings\"]\n",
    "    print(\"Type:\", type(br))\n",
    "    print(\"Shape:\", br.shape)\n",
    "    print(\"Dtype:\", br.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "740f42ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path, \"r\") as f:\n",
    "    br = f[\"behavioralRatings\"][:]   # turn into NumPy array, shape (2, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7bb3b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "# (2, 10, 20) to (20, 10, 2) in order to turn into same structure as matlab \n",
    "ratings = np.transpose(br, (2, 1, 0))\n",
    "\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e46e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "enjoyment = ratings[:, :, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a68f3616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>song_1</th>\n",
       "      <th>song_2</th>\n",
       "      <th>song_3</th>\n",
       "      <th>song_4</th>\n",
       "      <th>song_5</th>\n",
       "      <th>song_6</th>\n",
       "      <th>song_7</th>\n",
       "      <th>song_8</th>\n",
       "      <th>song_9</th>\n",
       "      <th>song_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject  song_1  song_2  song_3  song_4  song_5  song_6  song_7  song_8  \\\n",
       "0         1     8.0     8.0     5.0     5.0     9.0     7.0     6.0     7.0   \n",
       "1         2     8.0     8.0     7.0     5.0     3.0     7.0     5.0     5.0   \n",
       "2         3     8.0     7.0     8.0     6.0     8.0     7.0     7.0     8.0   \n",
       "3         4     8.0     7.0     2.0     7.0     9.0     6.0     7.0     7.0   \n",
       "4         5     6.0     8.0     6.0     5.0     7.0     7.0     8.0     7.0   \n",
       "5         6     4.0     5.0     4.0     5.0     5.0     5.0     4.0     4.0   \n",
       "6         7     6.0     2.0     2.0     5.0     3.0     7.0     3.0     5.0   \n",
       "7         8     5.0     8.0     3.0     7.0     5.0     6.0     6.0     6.0   \n",
       "8         9     7.0     5.0     6.0     5.0     6.0     5.0     4.0     6.0   \n",
       "9        10     5.0     4.0     2.0     7.0     5.0     6.0     4.0     7.0   \n",
       "10       11     7.0     5.0     2.0     4.0     7.0     9.0     7.0     8.0   \n",
       "11       12     9.0     6.0     6.0     8.0     6.0     7.0     6.0     8.0   \n",
       "12       13     6.0     7.0     5.0     9.0     7.0     7.0     6.0     8.0   \n",
       "13       14     3.0     5.0     5.0     6.0     5.0     6.0     4.0     6.0   \n",
       "14       15     7.0     4.0     4.0     3.0     5.0     5.0     3.0     6.0   \n",
       "15       16     6.0     5.0     4.0     6.0     5.0     5.0     7.0     6.0   \n",
       "16       17     5.0     6.0     4.0     5.0     7.0     7.0     4.0     6.0   \n",
       "17       18     9.0     7.0     8.0     9.0     9.0     9.0     9.0     9.0   \n",
       "18       19     7.0     6.0     6.0     8.0     5.0     8.0     5.0     7.0   \n",
       "19       20     8.0     8.0     2.0     6.0     8.0     9.0     4.0     6.0   \n",
       "\n",
       "    song_9  song_10  \n",
       "0      5.0      5.0  \n",
       "1      4.0      4.0  \n",
       "2      7.0      6.0  \n",
       "3      5.0      7.0  \n",
       "4      7.0      3.0  \n",
       "5      5.0      1.0  \n",
       "6      3.0      2.0  \n",
       "7      7.0      4.0  \n",
       "8      3.0      2.0  \n",
       "9      3.0      1.0  \n",
       "10     6.0      1.0  \n",
       "11     5.0      6.0  \n",
       "12     3.0      4.0  \n",
       "13     3.0      2.0  \n",
       "14     3.0      2.0  \n",
       "15     5.0      2.0  \n",
       "16     5.0      1.0  \n",
       "17     9.0      3.0  \n",
       "18     8.0      4.0  \n",
       "19     8.0      1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participants = np.arange(1, 21)\n",
    "songs = np.arange(1, 11)\n",
    "\n",
    "like_df = pd.DataFrame(enjoyment,\n",
    "                      index=participants,\n",
    "                      columns=[f\"song_{s}\" for s in songs]).rename_axis(\"subject\").reset_index()\n",
    "\n",
    "like_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aad60a",
   "metadata": {},
   "source": [
    "# Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically mapping freq to names/categories\n",
    "BANDS = {\n",
    "    \"delta\": (1, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 12),\n",
    "    \"beta\": (12, 30),\n",
    "    \"gamma_low\": (30, 45),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "755b0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bandpower(f, psd, fmin, fmax):\n",
    "    idx = (f >= fmin) & (f <= fmax)\n",
    "    return np.trapezoid(psd[idx], f[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6fd705",
   "metadata": {},
   "source": [
    "# Loading in Cleaned EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f228f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = []\n",
    "all_y = []\n",
    "participant_ids = []\n",
    "song_ids = []\n",
    "\n",
    "# they had weird mappings in the study, these numbers correspond to file names\n",
    "# looping through each song\n",
    "for song in range(21, 31):\n",
    "    # loads in the file\n",
    "    load_mat_file = loadmat(f\"../data/cleaned_eeg/song{song}_Imputed.mat\")\n",
    "    # gets the current song\n",
    "    data = load_mat_file[f\"data{song}\"]\n",
    "\n",
    "    fs = float(load_mat_file[\"fs\"].squeeze())\n",
    "\n",
    "    channels, time, participants = data.shape\n",
    "\n",
    "    # converting werid mappings to start at 1\n",
    "    song_idx = song - 20\n",
    "    song_label = like_df[f\"song_{song_idx}\"].to_numpy()\n",
    "\n",
    "    # loop through each participant\n",
    "    for participant in range(participants):\n",
    "        # get eeg data for given participant for the given song\n",
    "        eeg_participant = data[:, :, participant]\n",
    "\n",
    "        # this chunk just gets the band power for each participant for given song\n",
    "        feature_list = []\n",
    "        for channel in range(channels):\n",
    "            f, psd = welch(eeg_participant[channel, :], fs = fs, nperseg = 2 * int(fs))\n",
    "            for fmin, fmax in BANDS.values():\n",
    "                band_power = calculate_bandpower(f, psd, fmin, fmax)\n",
    "                feature_list.append(band_power)\n",
    "\n",
    "        feature_vec = np.log10(np.array(feature_list) + .000000000000000000001)\n",
    "        all_X.append(feature_vec)\n",
    "\n",
    "        # basically liked if score above 6, no like below 6\n",
    "        all_y.append(1 if song_label[participant] >= 6 else 0)\n",
    "        participant_ids.append(participant)\n",
    "        song_ids.append(song_idx)\n",
    "\n",
    "# Convert to usable format\n",
    "X_all = np.vstack(all_X)\n",
    "y_all = np.array(all_y)\n",
    "\n",
    "participant_ids = np.array(participant_ids)\n",
    "song_ids = np.array(song_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28c285c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeaveOneGroupOut()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "logo = LeaveOneGroupOut()\n",
    "X_scaled = scaler.fit_transform(X_all)\n",
    "logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adb43aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg_initial = LogisticRegression(max_iter=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e56c10",
   "metadata": {},
   "source": [
    "## Metrics for Logistic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24becbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics from aggregation across folds\n",
      "Acurracy across all folds:  0.5900000000000001\n",
      "Precision for Class 0:  0.5782738095238095\n",
      "Precision for Class 1:  0.3293452380952381\n",
      "Recall for Class 0:  0.6497222222222222\n",
      "Recall for Class 1:  0.41146825396825387\n",
      "------------------------------------\n",
      "Computing Precision Recall whole data set (not per fold)\n",
      "Precision for class 0:  0.680327868852459\n",
      "Precision for class 1:  0.44871794871794873\n",
      "Recall for class 0:  0.6587301587301587\n",
      "Recall for class 1:  0.47297297297297297\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "# collecting across all folds bc my prec recall kinda weird with some classes having none per fold\n",
    "all_folds_y_true = []\n",
    "all_folds_y_pred = []\n",
    "\n",
    "for train_idx, test_idx in logo.split(X_scaled, y_all, participant_ids):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y_all[train_idx], y_all[test_idx]\n",
    "\n",
    "    logistic_reg_initial.fit(X_train, y_train)\n",
    "    y_pred = logistic_reg_initial.predict(X_test)\n",
    "    y_prob = logistic_reg_initial.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    all_folds_y_true.extend(y_test)\n",
    "    all_folds_y_pred.extend(y_pred)\n",
    "\n",
    "    \n",
    "    # precisions.append(precision_score(y_test, y_pred, pos_label=1, zero_division = 0))\n",
    "    # recalls.append(recall_score(y_test, y_pred, pos_label = 1, zero_division=0))\n",
    "\n",
    "    prec, rec, f1, support = precision_recall_fscore_support(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        labels = [0,1],\n",
    "        average = None,\n",
    "        zero_division = 0\n",
    "    )\n",
    "\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "all_folds_y_true = np.array(all_folds_y_true)\n",
    "all_folds_y_pred = np.array(all_folds_y_pred)\n",
    "\n",
    "prec, rec, f1, support = precision_recall_fscore_support(\n",
    "    all_folds_y_true,\n",
    "    all_folds_y_pred,\n",
    "    labels = [0,1],\n",
    "    average = None,\n",
    "    zero_division = 0\n",
    ")\n",
    "\n",
    "# print(\"Precision across all folds: \", np.mean(precisions))\n",
    "# print(\"Recall across all folds: \", np.mean(recalls))\n",
    "\n",
    "precisions = np.array(precisions)\n",
    "recalls = np.array(recalls)\n",
    "\n",
    "mean_prec_class0, mean_prec_class1 = precisions.mean(axis = 0)\n",
    "mean_recall_class0, mean_recall_class1 = recalls.mean(axis = 0)\n",
    "\n",
    "print(\"Metrics from aggregation across folds\")\n",
    "print(\"Acurracy across all folds: \", np.mean(accuracies))\n",
    "\n",
    "print(\"Precision for Class 0: \", mean_prec_class0)\n",
    "print(\"Precision for Class 1: \", mean_prec_class1)\n",
    "\n",
    "print(\"Recall for Class 0: \", mean_recall_class0)\n",
    "print(\"Recall for Class 1: \", mean_recall_class1)\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"Computing Precision Recall whole data set (not per fold)\")\n",
    "\n",
    "print(\"Precision for class 0: \", prec[0])\n",
    "print(\"Precision for class 1: \", prec[1])\n",
    "\n",
    "print(\"Recall for class 0: \", rec[0])\n",
    "print(\"Recall for class 1: \", rec[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ae1eb1",
   "metadata": {},
   "source": [
    "## Metrics for Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e8ac48ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = SVC(\n",
    "    kernel = \"linear\",\n",
    "    C = 1,\n",
    "    probability = True,\n",
    "    class_weight = \"balanced\",\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15ebf02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics from aggregation across folds\n",
      "Acurracy across all folds:  0.595\n",
      "Precision for Class 0:  0.45083333333333336\n",
      "Precision for Class 1:  0.4608531746031746\n",
      "Recall for Class 0:  0.5059523809523812\n",
      "Recall for Class 1:  0.5356150793650795\n",
      "------------------------------------\n",
      "Computing Precision Recall whole data set (not per fold)\n",
      "Precision for class 0:  0.5543478260869565\n",
      "Precision for class 1:  0.6296296296296297\n",
      "Recall for class 0:  0.5604395604395604\n",
      "Recall for class 1:  0.6238532110091743\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "# collecting across all folds bc my prec recall kinda weird with some classes having none per fold\n",
    "all_folds_y_true = []\n",
    "all_folds_y_pred = []\n",
    "\n",
    "for train_idx, test_idx in logo.split(X_scaled, y_all, participant_ids):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y_all[train_idx], y_all[test_idx]\n",
    "\n",
    "    svm_linear.fit(X_train, y_train)\n",
    "    y_pred = svm_linear.predict(X_test)\n",
    "    y_prob = svm_linear.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    all_folds_y_true.extend(y_test)\n",
    "    all_folds_y_pred.extend(y_pred)\n",
    "\n",
    "    \n",
    "    # precisions.append(precision_score(y_test, y_pred, pos_label=1, zero_division = 0))\n",
    "    # recalls.append(recall_score(y_test, y_pred, pos_label = 1, zero_division=0))\n",
    "\n",
    "    prec, rec, f1, support = precision_recall_fscore_support(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        labels = [0,1],\n",
    "        average = None,\n",
    "        zero_division = 0\n",
    "    )\n",
    "\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "all_folds_y_true = np.array(all_folds_y_true)\n",
    "all_folds_y_pred = np.array(all_folds_y_pred)\n",
    "\n",
    "prec, rec, f1, support = precision_recall_fscore_support(\n",
    "    all_folds_y_true,\n",
    "    all_folds_y_pred,\n",
    "    labels = [0,1],\n",
    "    average = None,\n",
    "    zero_division = 0\n",
    ")\n",
    "\n",
    "# print(\"Precision across all folds: \", np.mean(precisions))\n",
    "# print(\"Recall across all folds: \", np.mean(recalls))\n",
    "\n",
    "precisions = np.array(precisions)\n",
    "recalls = np.array(recalls)\n",
    "\n",
    "mean_prec_class0, mean_prec_class1 = precisions.mean(axis = 0)\n",
    "mean_recall_class0, mean_recall_class1 = recalls.mean(axis = 0)\n",
    "\n",
    "print(\"Metrics from aggregation across folds\")\n",
    "print(\"Acurracy across all folds: \", np.mean(accuracies))\n",
    "\n",
    "print(\"Precision for Class 0: \", mean_prec_class0)\n",
    "print(\"Precision for Class 1: \", mean_prec_class1)\n",
    "\n",
    "print(\"Recall for Class 0: \", mean_recall_class0)\n",
    "print(\"Recall for Class 1: \", mean_recall_class1)\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"Computing Precision Recall whole data set (not per fold)\")\n",
    "\n",
    "print(\"Precision for class 0: \", prec[0])\n",
    "print(\"Precision for class 1: \", prec[1])\n",
    "\n",
    "print(\"Recall for class 0: \", rec[0])\n",
    "print(\"Recall for class 1: \", rec[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3763cdb0",
   "metadata": {},
   "source": [
    "# Messing with Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cbd16c",
   "metadata": {},
   "source": [
    "## Like >= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a34fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = []\n",
    "all_y = []\n",
    "participant_ids = []\n",
    "song_ids = []\n",
    "\n",
    "# they had weird mappings in the study, these numbers correspond to file names\n",
    "# looping through each song\n",
    "for song in range(21, 31):\n",
    "    # loads in the file\n",
    "    load_mat_file = loadmat(f\"../data/cleaned_eeg/song{song}_Imputed.mat\")\n",
    "    # gets the current song\n",
    "    data = load_mat_file[f\"data{song}\"]\n",
    "\n",
    "    fs = float(load_mat_file[\"fs\"].squeeze())\n",
    "\n",
    "    channels, time, participants = data.shape\n",
    "\n",
    "    # converting werid mappings to start at 1\n",
    "    song_idx = song - 20\n",
    "    song_label = like_df[f\"song_{song_idx}\"].to_numpy()\n",
    "\n",
    "    # loop through each participant\n",
    "    for participant in range(participants):\n",
    "        # get eeg data for given participant for the given song\n",
    "        eeg_participant = data[:, :, participant]\n",
    "\n",
    "        # this chunk just gets the band power for each participant for given song\n",
    "        feature_list = []\n",
    "        for channel in range(channels):\n",
    "            f, psd = welch(eeg_participant[channel, :], fs = fs, nperseg = 2 * int(fs))\n",
    "            for fmin, fmax in BANDS.values():\n",
    "                band_power = calculate_bandpower(f, psd, fmin, fmax)\n",
    "                feature_list.append(band_power)\n",
    "\n",
    "        feature_vec = np.log10(np.array(feature_list) + .000000000000000000001)\n",
    "        all_X.append(feature_vec)\n",
    "\n",
    "        # basically liked if score above 6, no like below 6\n",
    "        all_y.append(1 if song_label[participant] >= 5 else 0)\n",
    "        participant_ids.append(participant)\n",
    "        song_ids.append(song_idx)\n",
    "\n",
    "# Convert to usable format\n",
    "X_all = np.vstack(all_X)\n",
    "y_all = np.array(all_y)\n",
    "\n",
    "participant_ids = np.array(participant_ids)\n",
    "song_ids = np.array(song_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dc489bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeaveOneGroupOut()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "logo = LeaveOneGroupOut()\n",
    "X_scaled = scaler.fit_transform(X_all)\n",
    "logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d99c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg_initial = LogisticRegression(max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fee75f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics from aggregation across folds\n",
      "Acurracy across all folds:  0.615\n",
      "Precision for Class 0:  0.1894642857142857\n",
      "Precision for Class 1:  0.746388888888889\n",
      "Recall for Class 0:  0.3441666666666667\n",
      "Recall for Class 1:  0.6798015873015872\n",
      "------------------------------------\n",
      "Computing Precision Recall whole data set (not per fold)\n",
      "Precision for class 0:  0.296875\n",
      "Precision for class 1:  0.7647058823529411\n",
      "Recall for class 0:  0.37254901960784315\n",
      "Recall for class 1:  0.697986577181208\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "# collecting across all folds bc my prec recall kinda weird with some classes having none per fold\n",
    "all_folds_y_true = []\n",
    "all_folds_y_pred = []\n",
    "\n",
    "for train_idx, test_idx in logo.split(X_scaled, y_all, participant_ids):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y_all[train_idx], y_all[test_idx]\n",
    "\n",
    "    logistic_reg_initial.fit(X_train, y_train)\n",
    "    y_pred = logistic_reg_initial.predict(X_test)\n",
    "    y_prob = logistic_reg_initial.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    all_folds_y_true.extend(y_test)\n",
    "    all_folds_y_pred.extend(y_pred)\n",
    "\n",
    "    \n",
    "    # precisions.append(precision_score(y_test, y_pred, pos_label=1, zero_division = 0))\n",
    "    # recalls.append(recall_score(y_test, y_pred, pos_label = 1, zero_division=0))\n",
    "\n",
    "    prec, rec, f1, support = precision_recall_fscore_support(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        labels = [0,1],\n",
    "        average = None,\n",
    "        zero_division = 0\n",
    "    )\n",
    "\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "all_folds_y_true = np.array(all_folds_y_true)\n",
    "all_folds_y_pred = np.array(all_folds_y_pred)\n",
    "\n",
    "prec, rec, f1, support = precision_recall_fscore_support(\n",
    "    all_folds_y_true,\n",
    "    all_folds_y_pred,\n",
    "    labels = [0,1],\n",
    "    average = None,\n",
    "    zero_division = 0\n",
    ")\n",
    "\n",
    "# print(\"Precision across all folds: \", np.mean(precisions))\n",
    "# print(\"Recall across all folds: \", np.mean(recalls))\n",
    "\n",
    "precisions = np.array(precisions)\n",
    "recalls = np.array(recalls)\n",
    "\n",
    "mean_prec_class0, mean_prec_class1 = precisions.mean(axis = 0)\n",
    "mean_recall_class0, mean_recall_class1 = recalls.mean(axis = 0)\n",
    "\n",
    "print(\"Metrics from aggregation across folds\")\n",
    "print(\"Acurracy across all folds: \", np.mean(accuracies))\n",
    "\n",
    "print(\"Precision for Class 0: \", mean_prec_class0)\n",
    "print(\"Precision for Class 1: \", mean_prec_class1)\n",
    "\n",
    "print(\"Recall for Class 0: \", mean_recall_class0)\n",
    "print(\"Recall for Class 1: \", mean_recall_class1)\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"Computing Precision Recall whole data set (not per fold)\")\n",
    "\n",
    "print(\"Precision for class 0: \", prec[0])\n",
    "print(\"Precision for class 1: \", prec[1])\n",
    "\n",
    "print(\"Recall for class 0: \", rec[0])\n",
    "print(\"Recall for class 1: \", rec[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a00fe",
   "metadata": {},
   "source": [
    "## Like => score >= 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01d5232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = []\n",
    "all_y = []\n",
    "participant_ids = []\n",
    "song_ids = []\n",
    "\n",
    "# they had weird mappings in the study, these numbers correspond to file names\n",
    "# looping through each song\n",
    "for song in range(21, 31):\n",
    "    # loads in the file\n",
    "    load_mat_file = loadmat(f\"../data/cleaned_eeg/song{song}_Imputed.mat\")\n",
    "    # gets the current song\n",
    "    data = load_mat_file[f\"data{song}\"]\n",
    "\n",
    "    fs = float(load_mat_file[\"fs\"].squeeze())\n",
    "\n",
    "    channels, time, participants = data.shape\n",
    "\n",
    "    # converting werid mappings to start at 1\n",
    "    song_idx = song - 20\n",
    "    song_label = like_df[f\"song_{song_idx}\"].to_numpy()\n",
    "\n",
    "    # loop through each participant\n",
    "    for participant in range(participants):\n",
    "        # get eeg data for given participant for the given song\n",
    "        eeg_participant = data[:, :, participant]\n",
    "\n",
    "        # this chunk just gets the band power for each participant for given song\n",
    "        feature_list = []\n",
    "        for channel in range(channels):\n",
    "            f, psd = welch(eeg_participant[channel, :], fs = fs, nperseg = 2 * int(fs))\n",
    "            for fmin, fmax in BANDS.values():\n",
    "                band_power = calculate_bandpower(f, psd, fmin, fmax)\n",
    "                feature_list.append(band_power)\n",
    "\n",
    "        feature_vec = np.log10(np.array(feature_list) + .000000000000000000001)\n",
    "        all_X.append(feature_vec)\n",
    "\n",
    "        # basically liked if score above 6, no like below 6\n",
    "        all_y.append(1 if song_label[participant] >= 7 else 0)\n",
    "        participant_ids.append(participant)\n",
    "        song_ids.append(song_idx)\n",
    "\n",
    "# Convert to usable format\n",
    "X_all = np.vstack(all_X)\n",
    "y_all = np.array(all_y)\n",
    "\n",
    "participant_ids = np.array(participant_ids)\n",
    "song_ids = np.array(song_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1419dbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeaveOneGroupOut()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "logo = LeaveOneGroupOut()\n",
    "X_scaled = scaler.fit_transform(X_all)\n",
    "logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19d167b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg_initial = LogisticRegression(max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2406bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics from aggregation across folds\n",
      "Acurracy across all folds:  0.5900000000000001\n",
      "Precision for Class 0:  0.5782738095238095\n",
      "Precision for Class 1:  0.3293452380952381\n",
      "Recall for Class 0:  0.6497222222222222\n",
      "Recall for Class 1:  0.41146825396825387\n",
      "------------------------------------\n",
      "Computing Precision Recall whole data set (not per fold)\n",
      "Precision for class 0:  0.680327868852459\n",
      "Precision for class 1:  0.44871794871794873\n",
      "Recall for class 0:  0.6587301587301587\n",
      "Recall for class 1:  0.47297297297297297\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "# collecting across all folds bc my prec recall kinda weird with some classes having none per fold\n",
    "all_folds_y_true = []\n",
    "all_folds_y_pred = []\n",
    "\n",
    "for train_idx, test_idx in logo.split(X_scaled, y_all, participant_ids):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y_all[train_idx], y_all[test_idx]\n",
    "\n",
    "    logistic_reg_initial.fit(X_train, y_train)\n",
    "    y_pred = logistic_reg_initial.predict(X_test)\n",
    "    y_prob = logistic_reg_initial.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    all_folds_y_true.extend(y_test)\n",
    "    all_folds_y_pred.extend(y_pred)\n",
    "\n",
    "    \n",
    "    # precisions.append(precision_score(y_test, y_pred, pos_label=1, zero_division = 0))\n",
    "    # recalls.append(recall_score(y_test, y_pred, pos_label = 1, zero_division=0))\n",
    "\n",
    "    prec, rec, f1, support = precision_recall_fscore_support(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        labels = [0,1],\n",
    "        average = None,\n",
    "        zero_division = 0\n",
    "    )\n",
    "\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "all_folds_y_true = np.array(all_folds_y_true)\n",
    "all_folds_y_pred = np.array(all_folds_y_pred)\n",
    "\n",
    "prec, rec, f1, support = precision_recall_fscore_support(\n",
    "    all_folds_y_true,\n",
    "    all_folds_y_pred,\n",
    "    labels = [0,1],\n",
    "    average = None,\n",
    "    zero_division = 0\n",
    ")\n",
    "\n",
    "# print(\"Precision across all folds: \", np.mean(precisions))\n",
    "# print(\"Recall across all folds: \", np.mean(recalls))\n",
    "\n",
    "precisions = np.array(precisions)\n",
    "recalls = np.array(recalls)\n",
    "\n",
    "mean_prec_class0, mean_prec_class1 = precisions.mean(axis = 0)\n",
    "mean_recall_class0, mean_recall_class1 = recalls.mean(axis = 0)\n",
    "\n",
    "print(\"Metrics from aggregation across folds\")\n",
    "print(\"Acurracy across all folds: \", np.mean(accuracies))\n",
    "\n",
    "print(\"Precision for Class 0: \", mean_prec_class0)\n",
    "print(\"Precision for Class 1: \", mean_prec_class1)\n",
    "\n",
    "print(\"Recall for Class 0: \", mean_recall_class0)\n",
    "print(\"Recall for Class 1: \", mean_recall_class1)\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"Computing Precision Recall whole data set (not per fold)\")\n",
    "\n",
    "print(\"Precision for class 0: \", prec[0])\n",
    "print(\"Precision for class 1: \", prec[1])\n",
    "\n",
    "print(\"Recall for class 0: \", rec[0])\n",
    "print(\"Recall for class 1: \", rec[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "322d85da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.5       ],\n",
       "       [0.6       , 0.        ],\n",
       "       [0.25      , 1.        ],\n",
       "       [0.5       , 0.75      ],\n",
       "       [0.        , 0.6       ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9       , 0.        ],\n",
       "       [0.7       , 0.        ],\n",
       "       [0.83333333, 0.        ],\n",
       "       [0.85714286, 0.33333333],\n",
       "       [0.66666667, 0.75      ],\n",
       "       [1.        , 0.5       ],\n",
       "       [0.33333333, 0.42857143],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 0.1       ],\n",
       "       [1.        , 0.125     ],\n",
       "       [0.8       , 0.        ],\n",
       "       [0.125     , 1.        ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
